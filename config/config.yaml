# 1. PATHS
paths:
  raw: "data/raw"                      # onde estão os CSVs originais
  interim: "data/interim"              # saída do process.py
  processed: "data/processed"          # saída do feature.py
  cv_indices: "data/processed/cv_idx.pkl"

data:
  train: "data/processed/train.csv"
  test: "data/processed/test.csv"
  target_col: Personality
  id_col: id

# 2. PROCESSAMENTO BINÁRIO (process.py)
process:
  enable: true                         # ativa/desativa todo o script process.py
  encode_binomial:
    enable: true                       # aplica map 0/1
    binomial_map:
      "Yes": 1
      "No": 0
      "True": 1
      "False": 0
      Extrovert: 1
      Introvert: 0


# 3. FEATURE ENGINEERING (feature.py)
feature_engineering:
  enable: true                         # ativa/desativa feature.py (após process)
  steps:
    - flag_missing                     # adiciona is_null_* e any_missing
    - add_composite_mean               # média dos scores sociais
    - add_composite_pca                # PCA nos scores sociais
    - numeric_combinations             # combos numéricas
    - categorical_combinations         # combos categóricas

  flag_missing:
    enable: true

  add_composite_mean:
    enable: false
    cols:
      - Social_event_attendance
      - Going_outside
      - Friends_circle_size
      - Post_frequency

  add_composite_pca:
    enable: false
    cols:
      - Social_event_attendance
      - Going_outside
      - Friends_circle_size
      - Post_frequency
    n_components: 1
    scale_before: true

  numeric_combinations:
    enable: true
    cols:
      - Time_spent_Alone
      - Social_event_attendance
      - Going_outside
      - Friends_circle_size
      - Post_frequency
    operations:
      - product
      - diff
      # - ratio                       # descomente pra ativar
    eps: 1e-8

  categorical_combinations:
    enable: true
    cols:
      - Stage_fear
      - Drained_after_socializing
    sep: "_AND_"

# 4. CROSS-VALIDATION
cv:
  n_splits: 5
  shuffle: True
  random_state: 42

pipeline_steps:
  - name: imputation
    params:
      strategy: median
  - name: standardscaler
    params: {}


output:
  oof: output/oof_preds.csv
  test: output/test_preds.csv

mlflow_experiment: "pred_introverts_extroverts"

estimator:
#   name: random_forest
#   params:
#     n_estimators: 200         # número de árvores
#     max_depth: 8              # profundidade de cada árvore
#     max_features: sqrt        # sqrt(n_features)
#     min_samples_leaf: 5       # para evitar overfitting em outliers
#     random_state: 42

#   name: lgbm
#   params:
#     objective: binary
#     metric: binary_logloss
#     boosting_type: dart       # dart/gbdt para robustez contra overfit
#     n_estimators: 300
#     learning_rate: 0.05
#     num_leaves: 31
#     max_depth: 7
#     min_data_in_leaf: 20
#     subsample: 0.8
#     colsample_bytree: 0.8
#     reg_alpha: 1.0            # L1 regularization
#     reg_lambda: 1.0          # L2 regularization
#     random_state: 42

  name: catboost
  params:
    iterations: 300
    depth: 6
    learning_rate: 0.1
    class_weights: [1, 1]
    random_seed: 42
    verbose: 0

  # name: svm
  # params:
  #   C: 1.0
  #   kernel: rbf
  #   gamma: scale
  #   probability: true
  #   random_state: 42

#   name: gradient_boosting
#   params:
#     n_estimators: 200
#     learning_rate: 0.1
#     max_depth: 5
#     subsample: 0.8
#     max_features: sqrt
#     random_state: 42

  # name: logistic_regression   
  # params:
  #   C: 1.0
  #   penalty: l2
  #   max_iter: 100

#   name: xgbclassifier   # or logistic_regression | xgbclassifier
#   params:
#     objective: "binary:logistic"
#     eval_metric: logloss
#     max_depth: 4
#     eta: 0.01
#     subsample: 0.8
#     colsample_bytree: 0.8
#     random_state: 42

  # name: linear_svc
  # params:
  #   C: 1.0
  #   max_iter: 1000
  #   dual: False

  # name: nusvc
  # params:
  #   nu: 0.5
  #   kernel: rbf
  #   gamma: scale

  # name: svc
  # params:
  #   C: 1.0
  #   kernel: rbf
  #   gamma: auto
  #   probability: True

  # name: extra_tree
  # params:
  #   n_estimators: 100
  #   max_depth: 8
  #   random_state: 42

  # name: decision_tree
  # params:
  #   max_depth: 6
  #   min_samples_leaf: 5
  #   random_state: 42

  # name: knn
  # params:
  #   n_neighbors: 5
  #   weights: distance

  # name: nearest_centroid
  # params: {}  # sem parâmetros iniciais necessários

  # name: radius_neighbors
  # params:
  #   radius: 1.0
  #   weights: distance

  # name: logistic_regression_cv
  # params:
  #   Cs: [0.01, 0.1, 1.0, 10.0]
  #   cv: 5
  #   scoring: accuracy
  #   max_iter: 200

  # name: passive_aggressive
  # params:
  #   C: 1.0
  #   max_iter: 1000
  #   tol: 0_001

  # name: perceptron
  # params:
  #   max_iter: 1_000
  #   tol: 0_001

  # name: ridge
  # params:
  #   alpha: 1.0

  # name: ridge_cv
  # params:
  #   alphas: [0.1, 1.0, 10.0]
  #   cv: 5

  # name: sgd
  # params:
  #   loss: log_loss
  #   max_iter: 1000
  #   tol: 0_001
  #   penalty: l2

  # name: oneclass_svm
  # params:
  #   nu: 0.1
  #   tol: 0.001
